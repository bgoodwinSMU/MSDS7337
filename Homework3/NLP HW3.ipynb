{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8e04bc",
   "metadata": {},
   "source": [
    "Ben Goodwin\n",
    "\n",
    "NLP HW3\n",
    "\n",
    "2/8/22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fed833",
   "metadata": {},
   "source": [
    "1.Compare your given name with your nickname (if you don’t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "\n",
    "    a.\tWhat is the edit distance between your nickname and your given name?\n",
    "\n",
    "    b.\tWhat is the percentage string match between your nickname and your given name?\n",
    "\n",
    "Show your work for both calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d301244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do import things\n",
    "import nltk\n",
    "from difflib import SequenceMatcher\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e4c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Distance: 5\n",
      "Function Distance: 5\n"
     ]
    }
   ],
   "source": [
    "# string decleration\n",
    "source = 'Ben'\n",
    "target = 'Benjamin'\n",
    "#distance calculation\n",
    "distance=nltk.edit_distance(source , target )\n",
    "print('NLTK Distance:',distance)\n",
    "\n",
    "\n",
    "print('Function Distance:',editDis(source,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c86bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will also write a quick function to demonstrate this too\n",
    "def editDis(source, target):\n",
    "        sourceLen = len(source)\n",
    "        targetLeb = len(target)\n",
    "        dis =targetLeb - sourceLen\n",
    "        return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "597aa028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute percent string match\n",
    "def stringMatch(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9e33384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test out function\n",
    "stringMatch(\"Ben\",\"Benjamin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abc126",
   "metadata": {},
   "source": [
    " 2.\tFind a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "472e87b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MANY', 'YEARS', 'LATER', 'as', 'he', 'faced', 'the', 'firing', 'squad', ',', 'Colonel', 'Aureliano', 'Buendía', 'was', 'to', 'remember', 'that', 'distant', 'afternoon', 'when', 'his', 'father', 'took', 'him', 'to', 'discover', 'ice', '.', 'At', 'that', 'time', 'Macondo', 'was', 'a', 'village', 'of', 'twenty', 'adobe', 'houses', ',', 'built', 'on', 'the', 'bank', 'of', 'a', 'river', 'of', 'clear', 'water', 'that', 'ran', 'along', 'a', 'bed', 'of', 'polished', 'stones', ',', 'which', 'were', 'white', 'and', 'enormous', ',', 'like', 'prehistoric', 'eggs', '.']\n",
      "['MANY', 'YEARS', 'LATER', 'faced', 'firing', 'squad', ',', 'Colonel', 'Aureliano', 'Buendía', 'remember', 'distant', 'afternoon', 'father', 'took', 'discover', 'ice', '.', 'At', 'time', 'Macondo', 'village', 'twenty', 'adobe', 'houses', ',', 'built', 'bank', 'river', 'clear', 'water', 'ran', 'along', 'bed', 'polished', 'stones', ',', 'white', 'enormous', ',', 'like', 'prehistoric', 'eggs', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"\"\"MANY YEARS LATER as he faced the firing squad, Colonel Aureliano\n",
    "Buendía was to remember that distant afternoon when his father took him to\n",
    "discover ice. At that time Macondo was a village of twenty adobe houses, built on\n",
    "the bank of a river of clear water that ran along a bed of polished stones, which\n",
    "were white and enormous, like prehistoric eggs.\"\"\"\n",
    " \n",
    "stop_words = set(stopwords.words('english'))\n",
    " \n",
    "word_tokens = word_tokenize(example_sent)\n",
    " \n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    " \n",
    "filtered_sentence = []\n",
    " \n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    " \n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df006a",
   "metadata": {},
   "source": [
    "Did you friend correctly guess the book on the first try? \n",
    "\n",
    "Yes, in the case of the book \"100 Years of Solitude\" has one of the most famous opening lines of any book ever published.  It contains many words that aren't stop words that are immediately recgonizable as being from Gabriel Garcia Marquez's masterpiece.  Words like \"Aureliano Buendía, and Macondo.  These sentences are immediately identifiable with or without the stop words\n",
    "\n",
    "What did he or she guess?\n",
    "\n",
    "100 years of solitude\n",
    "\n",
    "\n",
    "Explain why you think you friend either was or was not able to guess the book from hearing the list of words.\n",
    "\n",
    "This is such and iconic first line to a book, it is extremely hard, having read the book to not recgonize this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f6147",
   "metadata": {},
   "source": [
    " 3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "627c44c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mani year later as he face the fire squad, colonel aureliano buendía wa to rememb that distant afternoon when hi father took him to discov ice.\n",
      "at that time macondo wa a villag of twenti adob houses, built on the bank of a river of clear water that ran along a bed of polish stones, which were white and enormous, like prehistor eggs.\n",
      "--------------------------------------------------\n",
      "\n",
      "First Sentence has 26 words and 20 valid stems with valid morphological roots\n",
      "Second Sentence has 37 words and 31 valid stems with valid morphological roots\n",
      "If you haven't read 100 years of solitude, fantastic book!!\n"
     ]
    }
   ],
   "source": [
    "#Initiate stemmer\n",
    "st = PorterStemmer()\n",
    "#Feed sentences into df\n",
    "text = ['MANY YEARS LATER as he faced the firing squad, Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice.',\n",
    "        'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs.',\n",
    "        ]\n",
    "#output df \n",
    "output = []\n",
    "#Stem each word\n",
    "for sentence in text:\n",
    "    output.append(\" \".join([st.stem(i) for i in sentence.split()]))\n",
    "#print stemmed words\n",
    "for item in output:\n",
    "    print(item)\n",
    "\n",
    "#Do some formatting and report results\n",
    "print(\"-\" * 50)\n",
    "print(\"\")\n",
    "    \n",
    "print(\"First Sentence has 26 words and 20 valid stems with valid morphological roots\")\n",
    "\n",
    "print(\"Second Sentence has 37 words and 31 valid stems with valid morphological roots\")\n",
    "\n",
    "print(\"If you haven't read 100 years of solitude, fantastic book!!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
