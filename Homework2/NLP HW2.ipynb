{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9324f1e4",
   "metadata": {},
   "source": [
    "Ben Goodwin\n",
    "\n",
    "NLP Homework 2\n",
    "\n",
    "1/24/2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83746ea5",
   "metadata": {},
   "source": [
    "1.\tIn Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. (Various methods will be discussed in the live session.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8a3cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring the libraries in\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "087ef78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12031294723785899\n"
     ]
    }
   ],
   "source": [
    "#Bring some texts in to compare and play with\n",
    "#These are the same texts I used for homework 1, with the addtion of a fourth text\n",
    "\n",
    "#Book title, Old-time Stories, Fairy Tales and Myths Retold by Children\n",
    "raw = open('talesandmyths.txt').read()\n",
    "raw = word_tokenize(raw)\n",
    "#print(lexical_diversity(raw)) #Fails long word method!\n",
    "\n",
    "#Book title, McGuffey's Fifth Eclectic Reader by William Holmes McGuffey\n",
    "raw1 = open('fifthelectronicreader.txt').read()\n",
    "raw1 = word_tokenize(raw1)\n",
    "\n",
    "#Book title, The Literary World Seventh Reader by Browne, Metcalf, and Withers\n",
    "raw2 = open('litearyworld.txt').read()\n",
    "raw2 = word_tokenize(raw2)\n",
    "\n",
    "#Test book, new text for this week\n",
    "raw3 = open('nature.txt').read()\n",
    "raw3 = word_tokenize(raw3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb77d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method scores the vocab size of a text\n",
    "#Input: Text\n",
    "#Return: score\n",
    "def score_vocab_size(text):\n",
    "    #Handles computing the vocab for the text\n",
    "    vocab = len(set(word.lower() for word in raw if word.isalpha()))\n",
    "    #Builds an array of vocabs based on history, plus the text passed to the function\n",
    "    x_array = np.array([969,10611,9708,vocab])\n",
    "    #Call to normalization fuction for 0,1 scale\n",
    "    normalized_arr = preprocessing.normalize([x_array])\n",
    "    #Get the score for the texted passed to the function\n",
    "    score = normalized_arr[0,3]\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adebd7d",
   "metadata": {},
   "source": [
    "This was an interesting problem that took a bit of thought.  I finally realized that normalization takes some previous data to scale the new input to.  For this function I took computed the vocab score for 3 other texts plus the text in question and used these as data points.  Then using the preprocessing.normalize function which behind the scenes computes: (zi = (xi – min(x)) / (max(x) – min(x))).  We then have a 0-1 scale built off of our data. The function then looks up the 4th entry in the array and returns the score of the vocab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2abb6151",
   "metadata": {},
   "source": [
    "2.\tAfter consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9171e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: text\n",
    "#Return: vocab_score/long_word_score (word_length >15)\n",
    "\n",
    "def long_word_score(text):\n",
    "    #Call vocab_score method on text\n",
    "    score = vocabulary_score(text)\n",
    "    #Iterate over text and determine which word_length >15\n",
    "    V = set(text)\n",
    "    long_words = [w for w in V if len(w) > 15]\n",
    "    #Length of list of long_words\n",
    "    long_words_len = len(long_words)\n",
    "    #Develop array with scores\n",
    "    x_array=np.array([539.3,353.7,539.34,score/long_words_len])\n",
    "    #Normalize data\n",
    "    normalized_arr = preprocessing.normalize([x_array])\n",
    "    #Retreive function input text\n",
    "    score = normalized_arr[0,3]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf53fe4",
   "metadata": {},
   "source": [
    "I actually solved this problem before I did number 1, I was initially confused by the term \"vocab score\".  I finally realized that normalization takes some previous data to scale the new input to.  For this function the idea of scaling is the same as above with another step.  In this function I consider vocab long if its greater than 15 characters.  I then determine the score by dividing the vocab score by the long word score (so the vocab score over the score of long words, essentially a metric of how many words are long words relative to the vocabulary.). The normalization follows suit, where the three training texts determine the scale, and then the fourth text is added and computed.  Finally the fourth element of the score array is returned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "235d1dc6",
   "metadata": {},
   "source": [
    "3.\tNow create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75e3b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    #Compute lexical diversity\n",
    "    lex_diversity = len(set(text)) / len(text)\n",
    "    #Build array with data plus data from function input\n",
    "    x_array=np.array([0.112959,0.12031294,0.0944273,lex_diversity])\n",
    "    #Normalize the data \n",
    "    normalized_arr = preprocessing.normalize([x_array])\n",
    "    #Retrieve function input text\n",
    "    score = normalized_arr[0,3]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4abd991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_difficulty_score(text):\n",
    "    #Call lexical diversity function\n",
    "    diversity = lexical_diversity(text)\n",
    "    #Call vocab score function\n",
    "    vocab_score= score_vocab_size(text)\n",
    "    #Call long word score\n",
    "    long_word_Score = long_word_score(text)\n",
    "    #Compute total score with equal weighting\n",
    "    total_score = (diversity*0.33333)+(vocab_score*0.33333)+(long_word_Score*0.33333)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a4ab7830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4114005240100155\n",
      "0.3186533674139358\n"
     ]
    }
   ],
   "source": [
    "#Test difficulty score (raw3 should be highest)\n",
    "print(text_difficulty_score(raw3))\n",
    "\n",
    "#Test difficulty score (raw1 should be lowest)\n",
    "print(text_difficulty_score(raw1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea371ccf",
   "metadata": {},
   "source": [
    "Luckily as expected the difficulty score is the highest for the fourth text (raw3).  This means to me that the function is working as expected.  \n",
    "\n",
    "The text difficulty score calls the lexical diversity function, vocab_score function, and long_word_score function and then computes a weighted average of each.  The total score is computed by multiplying each score by 3 and adding it to the other scores.  When applied to the texts from homework 1, the algorithms perform as expected with the first book ranking the easiest with the lowest difficulty score, and the latest book (not a childrens book) ranking the hardest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
